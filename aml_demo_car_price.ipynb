{
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# This is generated from https://ml.azure.com/visualinterface/authoring/Normal/a2d91bee-b325-48c9-acf7-77e79a400e55?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/amldemo/workspaces/amldemo-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
        "# To run this code, please install SDK by this command:\n",
        "# !pip install \"azure-ml-component[notebooks]\" --extra-index-url https://azuremlsdktestpypi.azureedge.net/modulesdkpreview --upgrade\n",
        "# More detailed guide to set up your environment: https://github.com/Azure/DesignerPrivatePreviewFeatures/blob/master/azure-ml-components/samples/setup-environment.ipynb\n",
        "# ------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "from azureml.core import Datastore\n",
        "from azure.ml.component import Pipeline, Component, dsl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# configure aml workspace\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get components\n",
        "azureml_split_data_func, azureml_evaluate_model_func, azureml_select_columns_in_dataset_func, azureml_train_model_func, azureml_clean_missing_data_func, azureml_decision_forest_regression_func, azureml_linear_regression_func, azureml_tune_model_hyperparameters_func, azureml_boosted_decision_tree_regression_func, azureml_score_model_func = Component.batch_load(ws, selectors=['azureml://Split Data', 'azureml://Evaluate Model', 'azureml://Select Columns in Dataset', 'azureml://Train Model', 'azureml://Clean Missing Data', 'azureml://Decision Forest Regression', 'azureml://Linear Regression', 'azureml://Tune Model Hyperparameters', 'azureml://Boosted Decision Tree Regression', 'azureml://Score Model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get dataset\n",
        "from azureml.core import Dataset\n",
        "if 'automobile_price_data_raw' not in ws.datasets:\n",
        "    datastore = Datastore.get(ws, 'azureml_globaldatasets')\n",
        "    dataset = Dataset.File.from_files((datastore, 'GenericCSV/Automobile_price_data_(Raw)'))\n",
        "    dataset.register(workspace=ws, name='automobile_price_data_raw', description='Clean missing data module required. Prices of various automobiles against make, model and technical specifications')\n",
        "automobile_price_data_raw = ws.datasets['automobile_price_data_raw']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define pipeline\n",
        "@dsl.pipeline(name='AML Demo Car Price', description='Pipeline created on 20211118', default_compute_target='amldemo-cluster', default_datastore='workspaceblobstore')\n",
        "def generated_pipeline():\n",
        "    azureml_select_columns_in_dataset_0 = azureml_select_columns_in_dataset_func(\n",
        "        dataset=automobile_price_data_raw,\n",
        "        select_columns='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"symboling\",\"make\",\"num-of-doors\",\"body-style\",\"engine-type\",\"engine-size\",\"horsepower\",\"city-mpg\",\"highway-mpg\",\"price\",\"num-of-cylinders\"]}]')\n",
        "    azureml_select_columns_in_dataset_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_select_columns_in_dataset_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_clean_missing_data_0 = azureml_clean_missing_data_func(\n",
        "        dataset=azureml_select_columns_in_dataset_0.outputs.results_dataset,\n",
        "        columns_to_be_cleaned='[\"AllColumns\"]',\n",
        "        minimum_missing_value_ratio=0.0,\n",
        "        maximum_missing_value_ratio=1.0,\n",
        "        cleaning_mode='Custom substitution value',\n",
        "        replacement_value='0',\n",
        "        generate_missing_value_indicator_column=False,\n",
        "        cols_with_all_missing_values='Remove')\n",
        "    azureml_clean_missing_data_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_clean_missing_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_split_data_0 = azureml_split_data_func(\n",
        "        dataset=azureml_clean_missing_data_0.outputs.cleaned_dataset,\n",
        "        splitting_mode='Split Rows',\n",
        "        fraction_of_rows_in_the_first_output_dataset=0.80,\n",
        "        randomized_split=True,\n",
        "        random_seed=123,\n",
        "        stratified_split='False',\n",
        "        regular_expression='\\\"column name\" ^start',\n",
        "        relational_expression='\\\"column name\" > 3')\n",
        "    azureml_split_data_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_split_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_linear_regression_0 = azureml_linear_regression_func(\n",
        "        solution_method='Ordinary Least Squares',\n",
        "        l2_regularization_weight=0.001,\n",
        "        include_intercept_term=True,\n",
        "        random_number_seed=None,\n",
        "        create_trainer_mode='SingleParameter',\n",
        "        learning_rate=0.1,\n",
        "        number_of_epochs_over_which_algorithm_iterates_through_examples=10,\n",
        "        l2_regularization_term_weight=0.001,\n",
        "        range_for_learning_rate='0.025; 0.05; 0.1; 0.2',\n",
        "        range_for_number_of_epochs_over_which_algorithm_iterates_through_examples='1; 10; 100',\n",
        "        range_for_l2_regularization_term_weight='0.001; 0.01; 0.1',\n",
        "        should_input_instances_be_normalized=True,\n",
        "        decrease_learning_rate_as_iterations_progress=True)\n",
        "    azureml_linear_regression_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_linear_regression_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_train_model_0 = azureml_train_model_func(\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset1,\n",
        "        untrained_model=azureml_linear_regression_0.outputs.untrained_model,\n",
        "        label_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"price\"]}]',\n",
        "        model_explanations=False)\n",
        "    azureml_train_model_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_train_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_score_model_0 = azureml_score_model_func(\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset2,\n",
        "        trained_model=azureml_train_model_0.outputs.trained_model,\n",
        "        append_score_columns_to_output=True)\n",
        "    azureml_score_model_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_score_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_boosted_decision_tree_regression_0 = azureml_boosted_decision_tree_regression_func(\n",
        "        create_trainer_mode='SingleParameter',\n",
        "        maximum_number_of_leaves_per_tree=20,\n",
        "        minimum_number_of_training_instances_required_to_form_a_leaf=10,\n",
        "        the_learning_rate=0.2,\n",
        "        total_number_of_trees_constructed=100,\n",
        "        random_number_seed=123,\n",
        "        range_for_maximum_number_of_leaves_per_tree='2; 8; 32; 128',\n",
        "        range_for_minimum_number_of_training_instances_required_to_form_a_leaf='1; 10; 50',\n",
        "        range_for_learning_rate='0.025; 0.05; 0.1; 0.2; 0.4',\n",
        "        range_for_total_number_of_trees_constructed='20; 100; 500')\n",
        "    azureml_boosted_decision_tree_regression_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_boosted_decision_tree_regression_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_train_model_1 = azureml_train_model_func(\n",
        "        untrained_model=azureml_boosted_decision_tree_regression_0.outputs.untrained_model,\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset1,\n",
        "        label_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"price\"]}]',\n",
        "        model_explanations=False)\n",
        "    azureml_train_model_1.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_train_model_1.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_score_model_1 = azureml_score_model_func(\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset2,\n",
        "        trained_model=azureml_train_model_1.outputs.trained_model,\n",
        "        append_score_columns_to_output=True)\n",
        "    azureml_score_model_1.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_score_model_1.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_evaluate_model_0 = azureml_evaluate_model_func(\n",
        "        scored_dataset=azureml_score_model_0.outputs.scored_dataset,\n",
        "        scored_dataset_to_compare=azureml_score_model_1.outputs.scored_dataset)\n",
        "    azureml_evaluate_model_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_evaluate_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_decision_forest_regression_0 = azureml_decision_forest_regression_func(\n",
        "        create_trainer_mode='SingleParameter',\n",
        "        number_of_decision_trees=8,\n",
        "        maximum_depth_of_the_decision_trees=32,\n",
        "        minimum_number_of_samples_per_leaf_node=1,\n",
        "        resampling_method='Bagging Resampling',\n",
        "        range_for_number_of_decision_trees='1; 8; 32',\n",
        "        range_for_the_maximum_depth_of_the_decision_trees='1; 16; 64',\n",
        "        range_for_the_minimum_number_of_samples_per_leaf_node='1; 4; 16')\n",
        "    azureml_decision_forest_regression_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_decision_forest_regression_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_tune_model_hyperparameters_0 = azureml_tune_model_hyperparameters_func(\n",
        "        training_dataset=azureml_split_data_0.outputs.results_dataset1,\n",
        "        untrained_model=azureml_decision_forest_regression_0.outputs.untrained_model,\n",
        "        specify_parameter_sweeping_mode='Random sweep',\n",
        "        maximum_number_of_runs_on_random_sweep=5,\n",
        "        random_seed=0,\n",
        "        name_or_numerical_index_of_the_label_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"price\"]}]',\n",
        "        metric_for_measuring_performance_for_classification='Accuracy',\n",
        "        metric_for_measuring_performance_for_regression='Mean absolute error')\n",
        "    azureml_tune_model_hyperparameters_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_tune_model_hyperparameters_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_score_model_2 = azureml_score_model_func(\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset2,\n",
        "        trained_model=azureml_tune_model_hyperparameters_0.outputs.trained_best_model,\n",
        "        append_score_columns_to_output=True)\n",
        "    azureml_score_model_2.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_score_model_2.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_evaluate_model_1 = azureml_evaluate_model_func(\n",
        "        scored_dataset_to_compare=azureml_score_model_2.outputs.scored_dataset,\n",
        "        scored_dataset=azureml_score_model_1.outputs.scored_dataset)\n",
        "    azureml_evaluate_model_1.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_evaluate_model_1.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a pipeline\n",
        "pipeline = generated_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# validate pipeline and visualize the graph\n",
        "pipeline.validate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# submit a pipeline run\n",
        "# pipeline.submit(experiment_name='sample-experiment-name').wait_for_completion()"
      ]
    }
  ]
}