{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/02_Training/02_Training_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline - Automated ML\n",
    "_**Training many models using Automated Machine Learning**_\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates how to train and register 11,973 models using Automated Machine Learning. We will utilize the AutoMLPipelineBuilder to parallelize the process of training 11,973 models. For this notebook we are using an orange juice sales dataset to predict the orange juice quantity for each brand and each store. For more information about the data refer to the Data Preparation Notebook.\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 20 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b> Please ensure you have the latest version of the SDK to ensure AutoML dependencies are consistent.</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade azureml-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade azureml-train-automl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the azureml-contrib-automl-pipeline-steps package that is needed for many models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-contrib-automl-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have already:\n",
    "\n",
    "1. Created your AML Workspace using the [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb)\n",
    "2. Run [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) to create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Set up workspace, datastore, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.env_variables import Env\n",
    "from utils.aml_workspace import Connect\n",
    "\n",
    "e=Env()\n",
    "\n",
    "# set up workspace\n",
    "ws = Connect().authenticate()\n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# set up datastores\n",
    "dstore = Datastore.get(ws, e.datastore_name)\n",
    "\n",
    "use_tabular = True\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Default datastore name'] = dstore.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: manymodels-training-pipeline\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, e.experiment_name)\n",
    "print('Experiment name: ' + experiment.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Call the registered filedataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 11,973 datasets and AutoMLPipelineBuilder to build 11,973 time-series to predict the quantity of each store brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset represents a brand's 2 years orange juice sales data that contains 7 columns and 122 rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to register the datasets in the Workspace first. The Data Preparation notebook demonstrates how to register two datasets to the workspace. \n",
    "\n",
    "The registered 'oj_data_small' file dataset contains the first 10 csv files and 'oj_data' contains all 11,973 csv files. You can choose to pass either filedatasets_10_models_input or filedatasets_all_models_inputs in the AutoMLPipelineBuilder.\n",
    "\n",
    "We recommend to **start with filedatasets_10_models** and make sure everything runs successfully, then scale up to filedatasets_all_models.\n",
    "\n",
    "### Option A\n",
    "\n",
    "You can now use Tabular reads of the CSV/Parquet files instead of having to use a File Data Sets.\n",
    "\n",
    "### Option B\n",
    "\n",
    "Using named file data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "if use_tabular:\n",
    "\n",
    "    ds_name_small = \"oj_sales_data_train\"\n",
    "    input_ds_small = Dataset.Tabular.from_delimited_files(\n",
    "        path=dstore.path(ds_name_small + \"/\"), validate=False\n",
    "    )\n",
    "\n",
    "    inference_name_small = \"oj_sales_data_inference\"\n",
    "    inference_ds_small = Dataset.Tabular.from_delimited_files(\n",
    "        path=dstore.path(inference_name_small + \"/\"), validate=False\n",
    "    )\n",
    "else:\n",
    "    filedst_10_models = Dataset.get_by_name(ws, name=e.dataset_name)\n",
    "    filedst_10_models_input = filedst_10_models.as_named_input('train_10_models')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Build the training pipeline\n",
    "Now that the dataset, WorkSpace, and datastore are set up, we can put together a pipeline for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a compute target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently AutoMLPipelineBuilder only supports AMLCompute. You can change to a different compute cluster if one fails.\n",
    "\n",
    "This is the compute target we will pass into our AutoMLPipelineBuilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "Checking cluster status...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = e.compute_name\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute = cts[amlcompute_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=e.vm_size,\n",
    "                                                           min_nodes=e.min_nodes,\n",
    "                                                           max_nodes=e.max_nodes)\n",
    "    # Create the cluster.\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    \n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "This dictionary defines the [AutoML settings](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py#parameters), for this forecasting task we add the name of the time column and the maximum forecast horizon.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**blocked_models**|Models in blocked_models won't be used by AutoML. All supported models can be found at [here](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.constants.supportedmodels.forecasting?view=azure-ml-py).|\n",
    "|**iterations**|Number of models to train. This is optional but provides customer with greater control.|\n",
    "|**iteration_timeout_minutes**|Maximum amount of time in minutes that the model can train. This is optional and depends on the dataset. We ask customer to explore a bit to get approximate times for training the dataset. For OJ dataset we set it 20 minutes|\n",
    "|**experiment_timeout_hours**|Maximum amount of time in hours that the experiment can take before it terminates.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "|**n_cross_validations**|Number of cross validation splits. Rolling Origin Validation is used to split time-series in a temporally consistent way.|\n",
    "|**enable_early_stopping**|Flag to enable early termination if the score is not improving in the short term.|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**max_horizon**|The number of periods out you would like to predict past your training data. Periods are inferred from your data.|\n",
    "|**grain_column_names**|The column names used to uniquely identify timeseries in data that has multiple rows with the same timestamp.|\n",
    "|**partition_column_names**|The names of columns used to group your models. For timeseries, the groups must not split up individual time-series. That is, each group must contain one or more whole time-series.|\n",
    "|**track_child_runs**|Flag to disable tracking of child runs. Only best run (metrics and model) is tracked if the flag is set to False.|\n",
    "|**pipeline_fetch_max_batch_size**|Determines how many pipelines (training algorithms) to fetch at a time for training, this helps reduce throttling when training at large scale.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from azureml.train.automl.runtime._many_models.many_models_parameters import (ManyModelsTrainParameters,)\n",
    "\n",
    "partition_column_names = ['Store', 'Brand']\n",
    "\n",
    "#automl_settings = {\n",
    "#    \"task\" : 'forecasting',\n",
    "#    \"primary_metric\" : 'normalized_root_mean_squared_error',\n",
    "#    \"iteration_timeout_minutes\" : 10, # This needs to be changed based on the dataset. We ask customer to explore how long training is taking before settings this value\n",
    "#    \"iterations\" : 5, # cut the number by 10 to make this go faster\n",
    "#    \"experiment_timeout_hours\" : 1,\n",
    "#    \"label_column_name\" : 'Quantity',\n",
    "#    \"n_cross_validations\" : 3,\n",
    "#    # \"verbosity\" : logging.INFO, \n",
    "#    # \"debug_log\": 'automl_oj_sales_debug.txt',\n",
    "#    \"time_column_name\": 'WeekStarting',\n",
    "#    \"drop_column_names\":\"Revenue\",   # might need to comment this whole line out for the scoring to work\n",
    "#    \"max_horizon\" : 20,\n",
    "#    \"track_child_runs\": False,\n",
    "#    \"grain_column_names\": partition_column_names,\n",
    "#    \"pipeline_fetch_max_batch_size\": 15\n",
    "#}\n",
    "\n",
    "automl_settings = {\n",
    "    \"task\": \"forecasting\",\n",
    "    \"primary_metric\": \"normalized_root_mean_squared_error\",\n",
    "    \"iteration_timeout_minutes\": 10,  # This needs to be changed based on the dataset. We ask customer to explore how long training is taking before settings this value\n",
    "    \"iterations\": 15,\n",
    "    \"experiment_timeout_hours\": 0.25,\n",
    "    \"label_column_name\": \"Quantity\",\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"time_column_name\": \"WeekStarting\",\n",
    "    \"drop_column_names\": \"Revenue\",\n",
    "    \"max_horizon\": 6,\n",
    "    \"grain_column_names\": partition_column_names,\n",
    "    \"track_child_runs\": False,\n",
    "}\n",
    "\n",
    "\n",
    "mm_paramters = ManyModelsTrainParameters(\n",
    "    automl_settings=automl_settings, partition_column_names=partition_column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build many model training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoMLPipelineBuilder is used to build the many models train step. You will need to determine the number of workers and nodes appropriate for your use case. The process_count_per_node is based off the number of cores of the compute VM. The node_count will determine the number of master nodes to use, increasing the node count will speed up the training process.\n",
    "\n",
    "* <b>experiment</b>: Current experiment.\n",
    "\n",
    "* <b>automl_settings</b>: AutoML settings dictionary.\n",
    "\n",
    "* <b>train_data</b>: Train dataset.\n",
    "\n",
    "* <b>compute_target</b>: Compute target for training.\n",
    "\n",
    "* <b>partition_column_names</b>: Partition column names.\n",
    "\n",
    "* <b>node_count</b>: The number of compute nodes to be used for running the user script. We recommend to start with 3 and increase the node_count if the training time is taking too long.\n",
    "\n",
    "* <b>process_count_per_node</b>: The number of processes per node.\n",
    "\n",
    "* <b>run_invocation_timeout</b>: The run() method invocation timeout in seconds. The timeout should be set to maximum training time of one AutoML run(with some buffer), by default it's 60 seconds.\n",
    "\n",
    "* <b>output_datastore</b>: Output datastore to output the training results.\n",
    "\n",
    "* <b>train_env(Optional)</b>: Optionally can provide train environment definition to use for training.\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 320 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azureml.contrib.automl.pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.get(ws, \"AzureML-AutoML\", label=\"Latest\")\n",
    "env.environment_variables = {'AZUREML_OUTPUT_UPLOAD_TIMEOUT_SEC':'7200'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class LinkTabularOutputDatasetConfig: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A partitioned tabular dataset will be created with the name training after many_models_train_data_partitioned_1634563244. You may use it for future training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter partition_keys: This is an experimental parameter, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "train_steps = AutoMLPipelineBuilder.get_many_models_train_steps(\n",
    "                                                            experiment=experiment,\n",
    "                                                            train_data=filedst_10_models_input,\n",
    "                                                            #train_data=input_ds_small,\n",
    "                                                            compute_target=compute,\n",
    "                                                            node_count=2,\n",
    "                                                            process_count_per_node=8,\n",
    "                                                            run_invocation_timeout=920,\n",
    "                                                            train_pipeline_parameters=mm_paramters, output_datastore=dstore)\n",
    "    \n",
    "\n",
    "#    experiment=experiment,\n",
    "#train_pipeline_parameters=mm_paramters,\n",
    "#train_data=input_ds_small,\n",
    "#                                                                train_data=filedst_10_models_input,\n",
    "#compute_target=compute,\n",
    "## partition_column_names=partition_column_names,\n",
    "#node_count=2,\n",
    "#process_count_per_node=8,\n",
    "#run_invocation_timeout=920,\n",
    "\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Run the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we submit our pipeline to run. The whole training pipeline takes about 1h 11m using a STANDARD_D16S_V3 VM with our current AutoMLPipelineBuilder setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step mm-data-partition [349534a1][2253f5bb-239c-464e-a2eb-f0a19e9ce663], (This step will run and generate new outputs)\n",
      "Created step many-models-train [bbeba00b][93b57aac-f59c-4af0-aa63-b4b857063620], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun ec1da44b-9626-4675-9d90-698c818a335c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ec1da44b-9626-4675-9d90-698c818a335c?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "#from azureml.widgets import RunDetails\n",
    "\n",
    "pipelineName = e.experiment_name\n",
    "pipeline = Pipeline(workspace=ws, steps=train_steps)\n",
    "# run = experiment.submit(pipeline, tags={\"BuildId\": os.environ.get(\"BUILDID\"), \"ComputeName\": e.vm_size})\n",
    "\n",
    "pipeline_run = Experiment(ws, pipelineName).submit(pipeline,  tags={\"BuildId\": os.environ.get(\"BUILDID\"), \"ComputeName\": e.vm_size})\n",
    "\n",
    "#RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the folowing command if you'd like to monitor the training process in jupyter notebook. It will stream logs live while training. \n",
    "\n",
    "**Note**: This command may not work for Notebook VM, however it should work on your local laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: ec1da44b-9626-4675-9d90-698c818a335c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ec1da44b-9626-4675-9d90-698c818a335c?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 4f608829-4e5c-49e1-8383-1b81b5971108\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/4f608829-4e5c-49e1-8383-1b81b5971108?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( mm-data-partition ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt\n",
      "========================================================================================================================\n",
      "2021-10-18T13:24:50Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/4f608829-4e5c-49e1-8383-1b81b5971108/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/4f608829-4e5c-49e1-8383-1b81b5971108/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=372671 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/4f608829-4e5c-49e1-8383-1b81b5971108/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-10-18T13:24:50Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/4f608829-4e5c-49e1-8383-1b81b5971108/mounts/workspaceblobstore\n",
      "2021-10-18T13:24:51Z The vmsize standard_d13_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-10-18T13:24:51Z Starting output-watcher...\n",
      "2021-10-18T13:24:51Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-10-18T13:24:51Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-10-18T13:24:51Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4d4668f442e87b2baa899f119bc648ab\n",
      "e4ca327ec0e7: Pulling fs layer\n",
      "f0fb8b64b41b: Pulling fs layer\n",
      "e43ee38068bf: Pulling fs layer\n",
      "409df78264bc: Pulling fs layer\n",
      "a2eb44ae9dc0: Pulling fs layer\n",
      "b8ff7afa1c52: Pulling fs layer\n",
      "d92dd21f7e9a: Pulling fs layer\n",
      "965946e36f3d: Pulling fs layer\n",
      "9d3ce4a2dac8: Pulling fs layer\n",
      "a9fe7eeca207: Pulling fs layer\n",
      "2a248e09f435: Pulling fs layer\n",
      "c97b92177ca6: Pulling fs layer\n",
      "47b361f3a680: Pulling fs layer\n",
      "7448a096891c: Pulling fs layer\n",
      "1351de473238: Pulling fs layer\n",
      "00fddd118b98: Pulling fs layer\n",
      "3ff88ee01a2d: Pulling fs layer\n",
      "1f7fa878e4b6: Pulling fs layer\n",
      "47b361f3a680: Waiting\n",
      "b8ff7afa1c52: Waiting\n",
      "a9fe7eeca207: Waiting\n",
      "7448a096891c: Waiting\n",
      "1351de473238: Waiting\n",
      "d92dd21f7e9a: Waiting\n",
      "00fddd118b98: Waiting\n",
      "965946e36f3d: Waiting\n",
      "3ff88ee01a2d: Waiting\n",
      "1f7fa878e4b6: Waiting\n",
      "2a248e09f435: Waiting\n",
      "c97b92177ca6: Waiting\n",
      "409df78264bc: Waiting\n",
      "a2eb44ae9dc0: Waiting\n",
      "9d3ce4a2dac8: Waiting\n",
      "e4ca327ec0e7: Verifying Checksum\n",
      "e4ca327ec0e7: Download complete\n",
      "409df78264bc: Verifying Checksum\n",
      "409df78264bc: Download complete\n",
      "e43ee38068bf: Verifying Checksum\n",
      "e43ee38068bf: Download complete\n",
      "b8ff7afa1c52: Verifying Checksum\n",
      "b8ff7afa1c52: Download complete\n",
      "e4ca327ec0e7: Pull complete\n",
      "d92dd21f7e9a: Verifying Checksum\n",
      "d92dd21f7e9a: Download complete\n",
      "965946e36f3d: Verifying Checksum\n",
      "965946e36f3d: Download complete\n",
      "9d3ce4a2dac8: Download complete\n",
      "a9fe7eeca207: Verifying Checksum\n",
      "a9fe7eeca207: Download complete\n",
      "2a248e09f435: Verifying Checksum\n",
      "2a248e09f435: Download complete\n",
      "c97b92177ca6: Verifying Checksum\n",
      "c97b92177ca6: Download complete\n",
      "47b361f3a680: Download complete\n",
      "f0fb8b64b41b: Verifying Checksum\n",
      "f0fb8b64b41b: Download complete\n",
      "a2eb44ae9dc0: Verifying Checksum\n",
      "a2eb44ae9dc0: Download complete\n",
      "1351de473238: Verifying Checksum\n",
      "1351de473238: Download complete\n",
      "00fddd118b98: Verifying Checksum\n",
      "00fddd118b98: Download complete\n",
      "1f7fa878e4b6: Download complete\n",
      "3ff88ee01a2d: Verifying Checksum\n",
      "3ff88ee01a2d: Download complete\n",
      "f0fb8b64b41b: Pull complete\n",
      "e43ee38068bf: Pull complete\n",
      "409df78264bc: Pull complete\n",
      "a2eb44ae9dc0: Pull complete\n",
      "b8ff7afa1c52: Pull complete\n",
      "d92dd21f7e9a: Pull complete\n",
      "965946e36f3d: Pull complete\n",
      "9d3ce4a2dac8: Pull complete\n",
      "a9fe7eeca207: Pull complete\n",
      "2a248e09f435: Pull complete\n",
      "c97b92177ca6: Pull complete\n",
      "47b361f3a680: Pull complete\n",
      "7448a096891c: Verifying Checksum\n",
      "7448a096891c: Download complete\n",
      "7448a096891c: Pull complete\n",
      "1351de473238: Pull complete\n",
      "00fddd118b98: Pull complete\n",
      "3ff88ee01a2d: Pull complete\n",
      "1f7fa878e4b6: Pull complete\n",
      "Digest: sha256:b029f65d9779366cc3ab575afad7e767036ac2e9989aa92e59f396866612b611\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_4d4668f442e87b2baa899f119bc648ab:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_4d4668f442e87b2baa899f119bc648ab:latest\n",
      "2021-10-18T13:25:41Z The vmsize standard_d13_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-10-18T13:25:41Z Check if container 4f608829-4e5c-49e1-8383-1b81b5971108 already exist exited with 0, \n",
      "\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt\n",
      "===============================================================================================================\n",
      "[2021-10-18T13:26:21.572125] Entering job preparation.\n",
      "[2021-10-18T13:26:23.230308] Starting job preparation.\n",
      "[2021-10-18T13:26:23.230349] Extracting the control code.\n",
      "[2021-10-18T13:26:23.230751] Starting extract_project.\n",
      "[2021-10-18T13:26:23.230810] Starting to extract zip file.\n",
      "[2021-10-18T13:26:23.249977] Finished extracting zip file.\n",
      "[2021-10-18T13:26:23.253670] Using urllib.request Python 3.0 or later\n",
      "[2021-10-18T13:26:23.253753] Start fetching snapshots.\n",
      "[2021-10-18T13:26:23.253832] Start fetching snapshot.\n",
      "[2021-10-18T13:26:23.253852] Retrieving project from snapshot: 072f0652-5eaa-4650-9700-3feac88b221c\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 47\n",
      "[2021-10-18T13:26:23.618206] Finished fetching snapshot.\n",
      "[2021-10-18T13:26:23.618251] Finished fetching snapshots.\n",
      "[2021-10-18T13:26:23.618259] Finished extract_project.\n",
      "[2021-10-18T13:26:23.618401] Finished fetching and extracting the control code.\n",
      "[2021-10-18T13:26:23.622944] downloadDataStore - Download from datastores if requested.\n",
      "[2021-10-18T13:26:23.624315] Start run_history_prep.\n",
      "[2021-10-18T13:26:23.635535] Entering context manager injector.\n",
      "[2021-10-18T13:26:23.640163] downloadDataStore completed\n",
      "[2021-10-18T13:26:23.641845] Job preparation is complete.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt\n",
      "===============================================================================================================\n",
      "[2021-10-18T13:26:48.988479] Entering job release\n",
      "[2021-10-18T13:26:50.472871] Starting job release\n",
      "[2021-10-18T13:26:50.473644] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 474\n",
      "[2021-10-18T13:26:50.474653] job release stage : upload_datastore starting...\n",
      "[2021-10-18T13:26:50.477635] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-10-18T13:26:50.484208] job release stage : execute_job_release starting...\n",
      "[2021-10-18T13:26:50.485159] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-10-18T13:26:50.485242] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-10-18T13:26:50.488127] Entering context manager injector.\n",
      "[2021-10-18T13:26:50.508534] job release stage : upload_datastore completed...\n",
      "[2021-10-18T13:26:50.576288] job release stage : send_run_telemetry starting...\n",
      "[2021-10-18T13:26:50.596213] get vm size and vm region successfully.\n",
      "[2021-10-18T13:26:50.605038] get compute meta data successfully.\n",
      "[2021-10-18T13:26:50.819015] job release stage : execute_job_release completed...\n",
      "[2021-10-18T13:26:50.974955] post artifact meta request successfully.\n",
      "[2021-10-18T13:26:51.013122] upload compute record artifact successfully.\n",
      "[2021-10-18T13:26:51.013204] job release stage : send_run_telemetry completed...\n",
      "[2021-10-18T13:26:51.013553] Job release is complete\n",
      "\n",
      "StepRun(mm-data-partition) Execution Summary\n",
      "=============================================\n",
      "StepRun( mm-data-partition ) Status: Finished\n",
      "{'runId': '4f608829-4e5c-49e1-8383-1b81b5971108', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2021-10-18T13:24:48.723441Z', 'endTimeUtc': '2021-10-18T13:27:02.681541Z', 'services': {}, 'properties': {'ContentSnapshotId': '072f0652-5eaa-4650-9700-3feac88b221c', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '2253f5bb-239c-464e-a2eb-f0a19e9ce663', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '349534a1', 'azureml.pipelinerunid': 'ec1da44b-9626-4675-9d90-698c818a335c', 'azureml.pipeline': 'ec1da44b-9626-4675-9d90-698c818a335c', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'partitioned_tabular_dataset': 'many_models_train_data_partitioned_1634563244'}, 'inputDatasets': [{'dataset': {'id': '3dfd13c1-554e-4845-8ed8-b89afc7c2820'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'many_models_train_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '865f74d0-f7be-4dc7-8d0a-5a0e830376b2', 'registeredId': '7aec0a73-9149-406f-bd7e-8ade64bdc7fd', 'registeredVersion': '1'}, 'outputType': 'Reference', 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'many_models_train_data_partitioned_1634563244/9ec12a6d-8cc9-40f5-a122-3058579a8950/*/*/*.parquet')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ReadParquetFile\",\n",
      "    \"AddColumnsFromPartitionFormat\",\n",
      "    \"DropColumns\",\n",
      "    \"SetColumnTypes\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"865f74d0-f7be-4dc7-8d0a-5a0e830376b2\",\n",
      "    \"name\": \"many_models_train_data_partitioned_1634563244\",\n",
      "    \"version\": 1,\n",
      "    \"workspace\": \"Workspace.create(name='coding-forge-ml-ws', subscription_id='af3877c2-18a2-4ce2-b67c-a8e21e968128', resource_group='coding-forge-rg')\"\n",
      "  }\n",
      "}}, {'identifier': {'savedId': '865f74d0-f7be-4dc7-8d0a-5a0e830376b2', 'registeredId': '7aec0a73-9149-406f-bd7e-8ade64bdc7fd', 'registeredVersion': '1'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'tabular_dataset_partition'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'many_models_train_data_partitioned_1634563244/9ec12a6d-8cc9-40f5-a122-3058579a8950/*/*/*.parquet')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ReadParquetFile\",\n",
      "    \"AddColumnsFromPartitionFormat\",\n",
      "    \"DropColumns\",\n",
      "    \"SetColumnTypes\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"865f74d0-f7be-4dc7-8d0a-5a0e830376b2\",\n",
      "    \"name\": \"many_models_train_data_partitioned_1634563244\",\n",
      "    \"version\": 1,\n",
      "    \"workspace\": \"Workspace.create(name='coding-forge-ml-ws', subscription_id='af3877c2-18a2-4ce2-b67c-a8e21e968128', resource_group='coding-forge-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'partition_training_dataset_wrapper.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--partitioned-dataset-name', 'many_models_train_data_partitioned_1634563244', '--training-runid', '__DEFAULT_ARG_VALUE', '--input-name', 'many_models_train_data', '--pipeline-scenario', 'many_models'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {}, 'data': {'many_models_train_data': {'dataLocation': {'dataset': {'id': '3dfd13c1-554e-4845-8ed8-b89afc7c2820', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'many_models_train_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'tabular_dataset_partition': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Link', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AutoML-AzureML-AutoML', 'version': 'Autosave_2021-10-18T13:21:16Z_6a587f33', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge', 'pytorch'], 'dependencies': ['python=3.6.2', 'pip=21.1.2', {'pip': ['azureml-core==1.34.0', 'azureml-pipeline-core==1.34.0', 'azureml-telemetry==1.34.0', 'azureml-defaults==1.34.0', 'azureml-interpret==1.34.0', 'azureml-responsibleai==1.34.0', 'azureml-automl-core==1.34.1', 'azureml-automl-runtime==1.34.1.post1', 'azureml-train-automl-client==1.34.0', 'azureml-train-automl-runtime==1.34.1', 'azureml-dataset-runtime==1.34.0', 'azureml-mlflow==1.34.0', 'inference-schema', 'py-cpuinfo==5.0.0', 'boto3==1.15.18', 'botocore==1.18.18']}, 'numpy~=1.18.0', 'scikit-learn==0.22.1', 'pandas~=0.25.0', 'py-xgboost<=0.90', 'fbprophet==0.5', 'holidays==0.9.11', 'setuptools-git', 'psutil>5.0.0,<6.0.0'], 'name': 'azureml_1b22a9c5d9b447e8fbdcc34171e02fe8'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1, 'location': None}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/azureml-logs/55_azureml-execution-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt?sv=2019-07-07&sr=b&sig=AgmNWlSlbw%2F5gxy8sgD%2FIBET%2Bh3YwuNFdNajk%2ByXsGQ%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'azureml-logs/65_job_prep-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/azureml-logs/65_job_prep-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt?sv=2019-07-07&sr=b&sig=j0wj3XVJ6eerd78PXCgh41pfMtcg1%2BjES1ap4u%2FBjJY%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=u8ecjAWCQoTFn%2FPmW%2FljmyUBKCrriQwo1bYHyRJCu90%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'azureml-logs/75_job_post-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/azureml-logs/75_job_post-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt?sv=2019-07-07&sr=b&sig=S6UMAA9aegQKAQdi455rEn%2B0oXAxO%2BBDeELEk0XDAIg%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'azureml-logs/process_info.json': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=FwkqRGAXMTAqaW4HldgCKtpiPgB6ylZI4TFBmu9eCek%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'azureml-logs/process_status.json': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=TEaD78sPLUZ3210ZxJDKhn%2FGKFml17BBq75Xz6jxjM4%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/99_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/99_azureml.log?sv=2019-07-07&sr=b&sig=2VHOBqhhHUzy9RUaxsHRA1dgIi34Ewtv6mY%2Bf7zKEBE%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=8bzFoMA%2BbPytM5nB5m2THMfndTVGJbUMJPjNc13Rtvg%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=UDmBIGm%2FE0scSmm7Zv4Okc6B3PXu9smmbMT9s66DC00%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=2bTOukpeRTCZ1khxNlSKVrvlXK%2BpuC2UILk4k3EEPGM%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=CeYtV4PAfvhiwj4Wz7JSRNhCoNfyyNxNY7TppWg9dIQ%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=UDOkZJOmTj7gJo2dYAgNizAEOFF3YLTaDLeAUNM3uoU%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=a456%2FebCGA89wPax%2BgQnAmEsYV5w45GmykM4GU8lnvw%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.4f608829-4e5c-49e1-8383-1b81b5971108/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=rEImAlGpluMrubUCFyuU%2BYfZ94OojvPpZx5XKmLz03w%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A16%3A51Z&se=2021-10-18T21%3A26%3A51Z&sp=r'}, 'submittedBy': 'Brandon Campbell'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: e9900d25-9821-4a16-bd96-8785697868a3\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e9900d25-9821-4a16-bd96-8785697868a3?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( many-models-train ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt\n",
      "========================================================================================================================\n",
      "2021-10-18T13:33:32Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=372671 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-10-18T13:33:32Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/mounts/workspaceblobstore\n",
      "2021-10-18T13:33:33Z The vmsize standard_d13_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-10-18T13:33:33Z Starting output-watcher...\n",
      "2021-10-18T13:33:33Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4d4668f442e87b2baa899f119bc648ab\n",
      "e4ca327ec0e7: Pulling fs layer\n",
      "f0fb8b64b41b: Pulling fs layer\n",
      "e43ee38068bf: Pulling fs layer\n",
      "409df78264bc: Pulling fs layer\n",
      "a2eb44ae9dc0: Pulling fs layer\n",
      "b8ff7afa1c52: Pulling fs layer\n",
      "d92dd21f7e9a: Pulling fs layer\n",
      "965946e36f3d: Pulling fs layer\n",
      "9d3ce4a2dac8: Pulling fs layer\n",
      "a9fe7eeca207: Pulling fs layer\n",
      "2a248e09f435: Pulling fs layer\n",
      "c97b92177ca6: Pulling fs layer\n",
      "47b361f3a680: Pulling fs layer\n",
      "7448a096891c: Pulling fs layer\n",
      "1351de473238: Pulling fs layer\n",
      "a2eb44ae9dc0: Waiting\n",
      "00fddd118b98: Pulling fs layer\n",
      "3ff88ee01a2d: Pulling fs layer\n",
      "1f7fa878e4b6: Pulling fs layer\n",
      "b8ff7afa1c52: Waiting\n",
      "d92dd21f7e9a: Waiting\n",
      "2a248e09f435: Waiting\n",
      "965946e36f3d: Waiting\n",
      "c97b92177ca6: Waiting\n",
      "9d3ce4a2dac8: Waiting\n",
      "47b361f3a680: Waiting\n",
      "a9fe7eeca207: Waiting\n",
      "1351de473238: Waiting\n",
      "409df78264bc: Waiting\n",
      "1f7fa878e4b6: Waiting\n",
      "3ff88ee01a2d: Waiting\n",
      "7448a096891c: Waiting\n",
      "e4ca327ec0e7: Verifying Checksum\n",
      "e4ca327ec0e7: Download complete\n",
      "409df78264bc: Verifying Checksum\n",
      "409df78264bc: Download complete\n",
      "e4ca327ec0e7: Pull complete\n",
      "a2eb44ae9dc0: Verifying Checksum\n",
      "a2eb44ae9dc0: Download complete\n",
      "b8ff7afa1c52: Verifying Checksum\n",
      "b8ff7afa1c52: Download complete\n",
      "e43ee38068bf: Verifying Checksum\n",
      "e43ee38068bf: Download complete\n",
      "965946e36f3d: Verifying Checksum\n",
      "965946e36f3d: Download complete\n",
      "9d3ce4a2dac8: Verifying Checksum\n",
      "9d3ce4a2dac8: Download complete\n",
      "a9fe7eeca207: Download complete\n",
      "2a248e09f435: Verifying Checksum\n",
      "2a248e09f435: Download complete\n",
      "d92dd21f7e9a: Verifying Checksum\n",
      "d92dd21f7e9a: Download complete\n",
      "f0fb8b64b41b: Verifying Checksum\n",
      "f0fb8b64b41b: Download complete\n",
      "c97b92177ca6: Verifying Checksum\n",
      "c97b92177ca6: Download complete\n",
      "47b361f3a680: Verifying Checksum\n",
      "47b361f3a680: Download complete\n",
      "1351de473238: Download complete\n",
      "00fddd118b98: Verifying Checksum\n",
      "00fddd118b98: Download complete\n",
      "1f7fa878e4b6: Verifying Checksum\n",
      "1f7fa878e4b6: Download complete\n",
      "3ff88ee01a2d: Verifying Checksum\n",
      "3ff88ee01a2d: Download complete\n",
      "f0fb8b64b41b: Pull complete\n",
      "e43ee38068bf: Pull complete\n",
      "409df78264bc: Pull complete\n",
      "a2eb44ae9dc0: Pull complete\n",
      "b8ff7afa1c52: Pull complete\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt\n",
      "===============================================================================================================\n",
      "[2021-10-18T13:33:35.898977] Entering job preparation.\n",
      "[2021-10-18T13:33:38.026493] Starting job preparation.\n",
      "[2021-10-18T13:33:38.026632] Extracting the control code.\n",
      "[2021-10-18T13:33:38.027067] Starting extract_project.\n",
      "[2021-10-18T13:33:38.027128] Starting to extract zip file.\n",
      "[2021-10-18T13:33:38.051739] Finished extracting zip file.\n",
      "[2021-10-18T13:33:38.055665] Using urllib.request Python 3.0 or later\n",
      "[2021-10-18T13:33:38.055718] Start fetching snapshots.\n",
      "[2021-10-18T13:33:38.055777] Start fetching snapshot.\n",
      "[2021-10-18T13:33:38.055800] Retrieving project from snapshot: 072f0652-5eaa-4650-9700-3feac88b221c\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 77\n",
      "[2021-10-18T13:33:38.400455] Finished fetching snapshot.\n",
      "[2021-10-18T13:33:38.400495] Start fetching snapshot.\n",
      "[2021-10-18T13:33:38.400510] Retrieving project from snapshot: e9df1d43-12e8-446c-9eb7-3475e476bb9e\n",
      "[2021-10-18T13:33:46.834000] Finished fetching snapshot.\n",
      "[2021-10-18T13:33:46.834043] Finished fetching snapshots.\n",
      "[2021-10-18T13:33:46.834053] Finished extract_project.\n",
      "[2021-10-18T13:33:46.834155] Finished fetching and extracting the control code.\n",
      "[2021-10-18T13:33:46.838105] downloadDataStore - Download from datastores if requested.\n",
      "[2021-10-18T13:33:46.839181] Start run_history_prep.\n",
      "[2021-10-18T13:33:46.852120] Entering context manager injector.\n",
      "Acquired lockfile /tmp/e9900d25-9821-4a16-bd96-8785697868a3-datastore.lock to downloading input data references\n",
      "[2021-10-18T13:33:47.838905] downloadDataStore completed\n",
      "[2021-10-18T13:33:47.842735] Job preparation is complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/10/18 13:35:19 Got JobInfoJson from env\n",
      "2021/10/18 13:35:19 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/10/18 13:35:19 Version: 3.0.01744.0001 Branch: .SourceBranch Commit: f3a69a2\n",
      "2021/10/18 13:35:19 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/10/18 13:35:19 Send process info logs to master server succeeded\n",
      "2021/10/18 13:35:19 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/10/18 13:35:19 Send process info logs to master server succeeded\n",
      "[2021-10-18T13:35:20.029477] Entering context manager injector.\n",
      "[2021-10-18T13:35:20.695180] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1048576', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/mounts/workspaceblobstore/azureml/e9900d25-9821-4a16-bd96-8785697868a3/many_models_training_output', '--process_count_per_node', '8', '--partition_keys', '[\"Store\", \"Brand\"]', '--node_count', '2', '--input_ds_0', 'partitioned_dataset'])\n",
      "Script type = None\n",
      "[2021-10-18T13:35:20.699683] Entering Run History Context Manager.\n",
      "[2021-10-18T13:35:23.468005] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/wd/azureml/e9900d25-9821-4a16-bd96-8785697868a3\n",
      "[2021-10-18T13:35:23.468364] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1048576', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/mounts/workspaceblobstore/azureml/e9900d25-9821-4a16-bd96-8785697868a3/many_models_training_output', '--process_count_per_node', '8', '--partition_keys', '[\"Store\", \"Brand\"]', '--node_count', '2', '--input_ds_0', 'partitioned_dataset']\n",
      "[2021-10-18T13:35:23.468852] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1048576', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/e9900d25-9821-4a16-bd96-8785697868a3/mounts/workspaceblobstore/azureml/e9900d25-9821-4a16-bd96-8785697868a3/many_models_training_output', '--process_count_per_node', '8', '--partition_keys', '[\"Store\", \"Brand\"]', '--node_count', '2', '--input_ds_0', 'partitioned_dataset']\n",
      "\n",
      "2021/10/18 13:35:24 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt\n",
      "===============================================================================================================\n",
      "[2021-10-18T13:41:25.439596] Entering job release\n",
      "[2021-10-18T13:41:27.225084] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-10-18T13:41:27.225159] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "StepRun(many-models-train) Execution Summary\n",
      "=============================================\n",
      "StepRun( many-models-train ) Status: Finished\n",
      "{'runId': 'e9900d25-9821-4a16-bd96-8785697868a3', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2021-10-18T13:33:25.078454Z', 'endTimeUtc': '2021-10-18T13:41:43.00287Z', 'services': {}, 'properties': {'ContentSnapshotId': '072f0652-5eaa-4650-9700-3feac88b221c', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '93b57aac-f59c-4af0-aa63-b4b857063620', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'bbeba00b', 'azureml.pipelinerunid': 'ec1da44b-9626-4675-9d90-698c818a335c', 'azureml.pipeline': 'ec1da44b-9626-4675-9d90-698c818a335c', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '865f74d0-f7be-4dc7-8d0a-5a0e830376b2'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'partitioned_dataset', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1048576', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_many_models_training_output', '--process_count_per_node', '8', '--partition_keys', '[\"Store\", \"Brand\"]', '--node_count', '2', '--input_ds_0', 'partitioned_dataset'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {'many_models_training_output': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/e9900d25-9821-4a16-bd96-8785697868a3/many_models_training_output', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'partitioned_dataset': {'dataLocation': {'dataset': {'id': '865f74d0-f7be-4dc7-8d0a-5a0e830376b2', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'partitioned_dataset', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AutoML-AzureML-AutoML', 'version': 'Autosave_2021-10-18T13:21:16Z_6a587f33', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge', 'pytorch'], 'dependencies': ['python=3.6.2', 'pip=21.1.2', {'pip': ['azureml-core==1.34.0', 'azureml-pipeline-core==1.34.0', 'azureml-telemetry==1.34.0', 'azureml-defaults==1.34.0', 'azureml-interpret==1.34.0', 'azureml-responsibleai==1.34.0', 'azureml-automl-core==1.34.1', 'azureml-automl-runtime==1.34.1.post1', 'azureml-train-automl-client==1.34.0', 'azureml-train-automl-runtime==1.34.1', 'azureml-dataset-runtime==1.34.0', 'azureml-mlflow==1.34.0', 'inference-schema', 'py-cpuinfo==5.0.0', 'boto3==1.15.18', 'botocore==1.18.18']}, 'numpy~=1.18.0', 'scikit-learn==0.22.1', 'pandas~=0.25.0', 'py-xgboost<=0.90', 'fbprophet==0.5', 'holidays==0.9.11', 'setuptools-git', 'psutil>5.0.0,<6.0.0'], 'name': 'azureml_1b22a9c5d9b447e8fbdcc34171e02fe8'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1, 'location': None}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/55_azureml-execution-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt?sv=2019-07-07&sr=b&sig=J%2FGas1aqsANS0Rngu3eFW5tQRBNeUd9uzlSfUEFKEdc%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/55_azureml-execution-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt?sv=2019-07-07&sr=b&sig=mactUpG3IbnyCvzhBAt1cMZyAAQ%2F5Nd9o8Zn%2FyLh73k%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/65_job_prep-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/65_job_prep-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt?sv=2019-07-07&sr=b&sig=T%2Bo31q6vi2isbDyeYwVBSU3K7OdUrLJM%2B6PFpngoKG8%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/65_job_prep-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/65_job_prep-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt?sv=2019-07-07&sr=b&sig=jhT4cAOVbKy9oXwXVbSaUoFymkhkrXEwkJxx28MIjJ4%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=wQbw00Ey3gljBYj2wY2RSZyIDOB5VMd%2Bzi4TNO%2F1t3w%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/75_job_post-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/75_job_post-tvmps_5dbc7b569d78f801b4a76c61b0f392409da22966fcf7e2dbdffa2fe5c5f19847_d.txt?sv=2019-07-07&sr=b&sig=Sr2wD8Ba3PNzVR1VaIrTyaGKE62e4X1GdDFSdrh747g%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/75_job_post-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/75_job_post-tvmps_6d56f5bcb0d26bafd74a515939a09e3b2f7b5535c7b99d6ed2bbcfad5cf50f03_d.txt?sv=2019-07-07&sr=b&sig=QFppScIr84sV%2F7VMQNfek4qHVWgj%2B%2F1HvjUz4AOezw4%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/process_info.json': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=N0r%2B5GpkvFvgm4%2FXLkGS27C1cnSifOor5aCwSWvsEEI%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'azureml-logs/process_status.json': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=enZmDMl93tVMQbnZWNxxNP17s%2FcXrufHdipeirflVUM%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/125_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/125_azureml.log?sv=2019-07-07&sr=b&sig=ELLq0UhV%2FlOxx25rfibuAAHf9NXz3UCfvmvEMok%2BMsg%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/141_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/141_azureml.log?sv=2019-07-07&sr=b&sig=QslheOEkwJ%2B7lRlmSFT37Cy80zu2BmFTT48j3MUZY4I%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Lw2vlQUo%2BS1JRvDdzuLKoO2Q%2BSyUZGSiRd3cglyChm0%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=VzVXzaQOG6ANdtw%2FsUWoSU1vD%2F9Y43mq4ttf%2BPPyb6I%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=czvuyNQAbCd1H3zxK5KjvOKl%2FJ%2BGgg78PLSmMf%2FuZwE%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=l2v2GBfYyI%2BYQO0eDNwO4V5WUd38BoFYYbIY7Pn8orE%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=YbAHx7euRp%2FsD0u1J%2B3GDbQdP7CfPyIv2B1bRkwI5M8%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=WpE6Kxes6qowZhST7KSOpQLARIYWbuUEzJVFKXqIovA%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.e9900d25-9821-4a16-bd96-8785697868a3/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Pkn7oIH%2Fd6dlgVuS1GtLBPGtippwPKG2Ndh5JYFBRGY%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A31%3A32Z&se=2021-10-18T21%3A41%3A32Z&sp=r'}, 'submittedBy': 'Brandon Campbell'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'ec1da44b-9626-4675-9d90-698c818a335c', 'status': 'Completed', 'startTimeUtc': '2021-10-18T13:21:12.653994Z', 'endTimeUtc': '2021-10-18T13:41:44.298111Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.ec1da44b-9626-4675-9d90-698c818a335c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=PnTTNkKRM0mcUZ8nDKL0hchFNmAIHWZ316G2nk5cBuE%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A33%3A28Z&se=2021-10-18T21%3A43%3A28Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.ec1da44b-9626-4675-9d90-698c818a335c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=GewlwRmzLaZXIYY2lniV4FRQZIT1Q75JpfLCahczAJ4%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A33%3A28Z&se=2021-10-18T21%3A43%3A28Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.ec1da44b-9626-4675-9d90-698c818a335c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=KzorOfmPhMDIr9JNCm4i2ZPPIaitAzt6sToBJnHnb18%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T13%3A33%3A28Z&se=2021-10-18T21%3A43%3A28Z&sp=r'}, 'submittedBy': 'Brandon Campbell'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run.wait_for_completion(show_output=True)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully trained, registered Automated ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Review outputs of the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training pipeline will train and register models to the Workspace. You can review trained models in the Azure Machine Learning Studio under 'Models'.\n",
    "If there are any issues with training, you can go to 'many-models-training' run under the pipeline run and explore logs under 'Logs'.\n",
    "You can look at the stdout and stderr output under logs/user/worker/<ip> for more details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Get list of AutoML runs along with registered model names and tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will iterate through all the automl runs for the experiment and list the details.\n",
    "\n",
    "**Framework** - AutoML, **Dataset** - input data set, **Run** - AutoML run id, **Status** - AutoML run status,  **Model** - Registered model name, **Tags** - Tags for model, **StartTime** - Start time, **EndTime** - End time, **ErrorType** - ErrorType, **ErrorCode** - ErrorCode, **ErrorMessage** - Error Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helper import get_training_output\n",
    "import os\n",
    "\n",
    "training_results_name = \"training_results\"\n",
    "training_output_name = \"many_models_training_output\"\n",
    "\n",
    "#training_file = get_training_output(run, training_results_name, training_output_name)\n",
    "training_file = get_training_output(pipeline_run, training_results_name, training_output_name)\n",
    "all_columns = [\"Framework\", \"Dataset\", \"Run\", \"Status\", \"Model\", \"Tags\", \"StartTime\", \"EndTime\" , \"ErrorType\", \"ErrorCode\", \"ErrorMessage\" ]\n",
    "df = pd.read_csv(training_file, delimiter=\" \", header=None, names=all_columns)\n",
    "training_csv_file = \"training.csv\"\n",
    "df.to_csv(training_csv_file)\n",
    "print(\"Training output has\", df.shape[0], \"rows. Please open\", os.path.abspath(training_csv_file), \"to browse through all the output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Publish and schedule the pipeline (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Publish the pipeline\n",
    "\n",
    "Once you have a pipeline you're happy with, you can publish a pipeline so you can call it programmatically later on. See this [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#publish-a-pipeline) for additional information on publishing and calling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "pipelineEndpointName = 'automl_train_many_models'\n",
    "\n",
    "published_pipeline = pipeline.publish(name = 'automl_train_many_models',\n",
    "                                  description = 'train many models',\n",
    "                                  version = '1',\n",
    "                                  continue_on_step_failure = False)\n",
    "\n",
    "\n",
    "if pipelineEndpointName in str(PipelineEndpoint.list(ws)):\n",
    "    # Add a new Version to an existing Endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.get(workspace = ws, name = pipelineEndpointName)\n",
    "    pipeline_endpoint.add_default(published_pipeline)\n",
    "else:\n",
    "    # Create a new Endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.publish(workspace = ws,\n",
    "                                                name = pipelineEndpointName,\n",
    "                                                pipeline = published_pipeline,\n",
    "                                                description = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Schedule the pipeline\n",
    "You can also [schedule the pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines) to run on a time-based or change-based schedule. This could be used to automatically retrain models every month or based on another trigger such as data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# training_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"automl_training_recurring_schedule\", \n",
    "#                             description=\"Schedule Training Pipeline to run on the first day of every month\",\n",
    "#                             pipeline_id=training_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Bookkeeping of workspace (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Cancel any runs that are running\n",
    "\n",
    "To cancel any runs that are still running in a given experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.helper import cancel_runs_in_experiment\n",
    "# failed_experiment =  'Please modify this and enter the experiment name'\n",
    "# # Please note that the following script cancels all the currently running runs in the experiment\n",
    "# cancel_runs_in_experiment(ws, failed_experiment)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "interpreter": {
   "hash": "3fec610cbb67958716dc318121910cfa04ded6f5645ced1eebbb9789e5469472"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('azureml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
