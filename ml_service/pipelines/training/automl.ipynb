{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/02_Training/02_Training_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline - Automated ML\n",
    "_**Training many models using Automated Machine Learning**_\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates how to train and register 11,973 models using Automated Machine Learning. We will utilize the AutoMLPipelineBuilder to parallelize the process of training 11,973 models. For this notebook we are using an orange juice sales dataset to predict the orange juice quantity for each brand and each store. For more information about the data refer to the Data Preparation Notebook.\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 20 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b> Please ensure you have the latest version of the SDK to ensure AutoML dependencies are consistent.</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade azureml-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade azureml-train-automl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the azureml-contrib-automl-pipeline-steps package that is needed for many models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-contrib-automl-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have already:\n",
    "\n",
    "1. Created your AML Workspace using the [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb)\n",
    "2. Run [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) to create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Set up workspace, datastore, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.env_variables import Env\n",
    "from utils.aml_workspace import Connect\n",
    "\n",
    "e=Env()\n",
    "\n",
    "# set up workspace\n",
    "ws = Connect().authenticate()\n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# set up datastores\n",
    "dstore = Datastore.get(ws, e.datastore_name)\n",
    "\n",
    "use_tabular = False\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Default datastore name'] = dstore.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: manymodels-training-pipeline\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, e.experiment_name)\n",
    "print('Experiment name: ' + experiment.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Call the registered filedataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 11,973 datasets and AutoMLPipelineBuilder to build 11,973 time-series to predict the quantity of each store brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset represents a brand's 2 years orange juice sales data that contains 7 columns and 122 rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to register the datasets in the Workspace first. The Data Preparation notebook demonstrates how to register two datasets to the workspace. \n",
    "\n",
    "The registered 'oj_data_small' file dataset contains the first 10 csv files and 'oj_data' contains all 11,973 csv files. You can choose to pass either filedatasets_10_models_input or filedatasets_all_models_inputs in the AutoMLPipelineBuilder.\n",
    "\n",
    "We recommend to **start with filedatasets_10_models** and make sure everything runs successfully, then scale up to filedatasets_all_models.\n",
    "\n",
    "### Option A\n",
    "\n",
    "You can now use Tabular reads of the CSV/Parquet files instead of having to use a File Data Sets.\n",
    "\n",
    "### Option B\n",
    "\n",
    "Using named file data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "if use_tabular:\n",
    "\n",
    "    ds_name_small = \"oj_sales_data_train\"\n",
    "    input_ds_small = Dataset.Tabular.from_delimited_files(\n",
    "        path=dstore.path(ds_name_small + \"/\"), validate=False\n",
    "    )\n",
    "\n",
    "    inference_name_small = \"oj_sales_data_inference\"\n",
    "    inference_ds_small = Dataset.Tabular.from_delimited_files(\n",
    "        path=dstore.path(inference_name_small + \"/\"), validate=False\n",
    "    )\n",
    "else:\n",
    "    filedst_10_models = Dataset.get_by_name(ws, name=e.dataset_name)\n",
    "    filedst_10_models_input = filedst_10_models.as_named_input('train_10_models')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Build the training pipeline\n",
    "Now that the dataset, WorkSpace, and datastore are set up, we can put together a pipeline for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a compute target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently AutoMLPipelineBuilder only supports AMLCompute. You can change to a different compute cluster if one fails.\n",
    "\n",
    "This is the compute target we will pass into our AutoMLPipelineBuilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "Checking cluster status...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = e.compute_name\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute = cts[amlcompute_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=e.vm_size,\n",
    "                                                           min_nodes=e.min_nodes,\n",
    "                                                           max_nodes=e.max_nodes)\n",
    "    # Create the cluster.\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    \n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "This dictionary defines the [AutoML settings](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py#parameters), for this forecasting task we add the name of the time column and the maximum forecast horizon.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**blocked_models**|Models in blocked_models won't be used by AutoML. All supported models can be found at [here](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.constants.supportedmodels.forecasting?view=azure-ml-py).|\n",
    "|**iterations**|Number of models to train. This is optional but provides customer with greater control.|\n",
    "|**iteration_timeout_minutes**|Maximum amount of time in minutes that the model can train. This is optional and depends on the dataset. We ask customer to explore a bit to get approximate times for training the dataset. For OJ dataset we set it 20 minutes|\n",
    "|**experiment_timeout_hours**|Maximum amount of time in hours that the experiment can take before it terminates.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "|**n_cross_validations**|Number of cross validation splits. Rolling Origin Validation is used to split time-series in a temporally consistent way.|\n",
    "|**enable_early_stopping**|Flag to enable early termination if the score is not improving in the short term.|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**max_horizon**|The number of periods out you would like to predict past your training data. Periods are inferred from your data.|\n",
    "|**grain_column_names**|The column names used to uniquely identify timeseries in data that has multiple rows with the same timestamp.|\n",
    "|**partition_column_names**|The names of columns used to group your models. For timeseries, the groups must not split up individual time-series. That is, each group must contain one or more whole time-series.|\n",
    "|**track_child_runs**|Flag to disable tracking of child runs. Only best run (metrics and model) is tracked if the flag is set to False.|\n",
    "|**pipeline_fetch_max_batch_size**|Determines how many pipelines (training algorithms) to fetch at a time for training, this helps reduce throttling when training at large scale.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from azureml.train.automl.runtime._many_models.many_models_parameters import (ManyModelsTrainParameters,)\n",
    "\n",
    "partition_column_names = ['Store', 'Brand']\n",
    "\n",
    "#automl_settings = {\n",
    "#    \"task\" : 'forecasting',\n",
    "#    \"primary_metric\" : 'normalized_root_mean_squared_error',\n",
    "#    \"iteration_timeout_minutes\" : 10, # This needs to be changed based on the dataset. We ask customer to explore how long training is taking before settings this value\n",
    "#    \"iterations\" : 5, # cut the number by 10 to make this go faster\n",
    "#    \"experiment_timeout_hours\" : 1,\n",
    "#    \"label_column_name\" : 'Quantity',\n",
    "#    \"n_cross_validations\" : 3,\n",
    "#    # \"verbosity\" : logging.INFO, \n",
    "#    # \"debug_log\": 'automl_oj_sales_debug.txt',\n",
    "#    \"time_column_name\": 'WeekStarting',\n",
    "#    \"drop_column_names\":\"Revenue\",   # might need to comment this whole line out for the scoring to work\n",
    "#    \"max_horizon\" : 20,\n",
    "#    \"track_child_runs\": False,\n",
    "#    \"grain_column_names\": partition_column_names,\n",
    "#    \"pipeline_fetch_max_batch_size\": 15\n",
    "#}\n",
    "\n",
    "automl_settings = {\n",
    "    \"task\": \"forecasting\",\n",
    "    \"primary_metric\": \"normalized_root_mean_squared_error\",\n",
    "    \"iteration_timeout_minutes\": 10,  # This needs to be changed based on the dataset. We ask customer to explore how long training is taking before settings this value\n",
    "    \"iterations\": 15,\n",
    "    \"experiment_timeout_hours\": 0.25,\n",
    "    \"label_column_name\": \"Quantity\",\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"time_column_name\": \"WeekStarting\",\n",
    "    \"drop_column_names\": \"Revenue\",\n",
    "    \"max_horizon\": 6,\n",
    "    \"grain_column_names\": partition_column_names,\n",
    "    \"track_child_runs\": False,\n",
    "}\n",
    "\n",
    "\n",
    "mm_paramters = ManyModelsTrainParameters(\n",
    "    automl_settings=automl_settings, partition_column_names=partition_column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build many model training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoMLPipelineBuilder is used to build the many models train step. You will need to determine the number of workers and nodes appropriate for your use case. The process_count_per_node is based off the number of cores of the compute VM. The node_count will determine the number of master nodes to use, increasing the node count will speed up the training process.\n",
    "\n",
    "* <b>experiment</b>: Current experiment.\n",
    "\n",
    "* <b>automl_settings</b>: AutoML settings dictionary.\n",
    "\n",
    "* <b>train_data</b>: Train dataset.\n",
    "\n",
    "* <b>compute_target</b>: Compute target for training.\n",
    "\n",
    "* <b>partition_column_names</b>: Partition column names.\n",
    "\n",
    "* <b>node_count</b>: The number of compute nodes to be used for running the user script. We recommend to start with 3 and increase the node_count if the training time is taking too long.\n",
    "\n",
    "* <b>process_count_per_node</b>: The number of processes per node.\n",
    "\n",
    "* <b>run_invocation_timeout</b>: The run() method invocation timeout in seconds. The timeout should be set to maximum training time of one AutoML run(with some buffer), by default it's 60 seconds.\n",
    "\n",
    "* <b>output_datastore</b>: Output datastore to output the training results.\n",
    "\n",
    "* <b>train_env(Optional)</b>: Optionally can provide train environment definition to use for training.\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 320 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azureml.contrib.automl.pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.get(ws, \"AzureML-AutoML\", label=\"Latest\")\n",
    "env.environment_variables = {'AZUREML_OUTPUT_UPLOAD_TIMEOUT_SEC':'7200'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "train_steps = AutoMLPipelineBuilder.get_many_models_train_steps(\n",
    "                                                            experiment=experiment,\n",
    "                                                            train_data=filedst_10_models_input,\n",
    "                                                            #train_data=input_ds_small,\n",
    "                                                            compute_target=compute,\n",
    "                                                            node_count=2,\n",
    "                                                            process_count_per_node=8,\n",
    "                                                            run_invocation_timeout=920,\n",
    "                                                            train_pipeline_parameters=mm_paramters, output_datastore=dstore)\n",
    "    \n",
    "\n",
    "#    experiment=experiment,\n",
    "#train_pipeline_parameters=mm_paramters,\n",
    "#train_data=input_ds_small,\n",
    "#                                                                train_data=filedst_10_models_input,\n",
    "#compute_target=compute,\n",
    "## partition_column_names=partition_column_names,\n",
    "#node_count=2,\n",
    "#process_count_per_node=8,\n",
    "#run_invocation_timeout=920,\n",
    "\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Run the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we submit our pipeline to run. The whole training pipeline takes about 1h 11m using a STANDARD_D16S_V3 VM with our current AutoMLPipelineBuilder setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step many-models-train [b51fecf5][ea2963f2-45e7-4ffd-b990-ca1a7d59e51f], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 5820d0fb-d764-48d4-a716-71fce75efe27\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5820d0fb-d764-48d4-a716-71fce75efe27?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "#from azureml.widgets import RunDetails\n",
    "\n",
    "pipelineName = e.experiment_name\n",
    "pipeline = Pipeline(workspace=ws, steps=train_steps)\n",
    "# run = experiment.submit(pipeline, tags={\"BuildId\": os.environ.get(\"BUILDID\"), \"ComputeName\": e.vm_size})\n",
    "\n",
    "pipeline_run = Experiment(ws, pipelineName).submit(pipeline,  tags={\"BuildId\": os.environ.get(\"BUILDID\"), \"ComputeName\": e.vm_size})\n",
    "\n",
    "#RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the folowing command if you'd like to monitor the training process in jupyter notebook. It will stream logs live while training. \n",
    "\n",
    "**Note**: This command may not work for Notebook VM, however it should work on your local laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 5820d0fb-d764-48d4-a716-71fce75efe27\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5820d0fb-d764-48d4-a716-71fce75efe27?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 9bb88f76-43a2-4327-942f-9c37a7645139\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9bb88f76-43a2-4327-942f-9c37a7645139?wsid=/subscriptions/af3877c2-18a2-4ce2-b67c-a8e21e968128/resourcegroups/coding-forge-rg/workspaces/coding-forge-ml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( many-models-train ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt\n",
      "========================================================================================================================\n",
      "2021-10-18T14:31:39Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=372671 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-10-18T14:31:39Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/mounts/workspaceblobstore\n",
      "2021-10-18T14:31:39Z The vmsize standard_d13_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-10-18T14:31:39Z Starting output-watcher...\n",
      "2021-10-18T14:31:39Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "2d4a7041ee64: Pulling fs layer\n",
      "9b5c830079c4: Pulling fs layer\n",
      "339038bcce95: Pulling fs layer\n",
      "c691bda31596: Pulling fs layer\n",
      "5050e24af0d7: Pulling fs layer\n",
      "87ce02e9f0c4: Pulling fs layer\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b5c830079c4: Waiting\n",
      "339038bcce95: Waiting\n",
      "c691bda31596: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "5050e24af0d7: Waiting\n",
      "87ce02e9f0c4: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "2d4a7041ee64: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "33f6d5f2e001: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "fb52bde70123: Verifying Checksum\n",
      "fb52bde70123: Download complete\n",
      "64788f86be3f: Download complete\n",
      "33f6d5f2e001: Verifying Checksum\n",
      "33f6d5f2e001: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "6ee7c3767844: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "2d4a7041ee64: Verifying Checksum\n",
      "2d4a7041ee64: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "339038bcce95: Verifying Checksum\n",
      "c691bda31596: Verifying Checksum\n",
      "c691bda31596: Download complete\n",
      "64788f86be3f: Pull complete\n",
      "5050e24af0d7: Download complete\n",
      "87ce02e9f0c4: Verifying Checksum\n",
      "87ce02e9f0c4: Download complete\n",
      "33f6d5f2e001: Pull complete\n",
      "9b5c830079c4: Verifying Checksum\n",
      "9b5c830079c4: Download complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "2d4e93adbf58: Pull complete\n",
      "6ee7c3767844: Pull complete\n",
      "62cfc3ccb8ab: Pull complete\n",
      "4a7af9d757ee: Pull complete\n",
      "2d4a7041ee64: Pull complete\n",
      "9b5c830079c4: Pull complete\n",
      "339038bcce95: Pull complete\n",
      "c691bda31596: Pull complete\n",
      "5050e24af0d7: Pull complete\n",
      "87ce02e9f0c4: Pull complete\n",
      "Digest: sha256:ebba444591b1e23c159b5a960c7b0236ca766b90ad7c79e1b4b9731a8a4845e4\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_30c8b4102ff1b91d5efbf92a55b8441f:latest\n",
      "2021-10-18T14:31:56Z The vmsize standard_d13_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-10-18T14:31:56Z Check if container 9bb88f76-43a2-4327-942f-9c37a7645139_DataSidecar already exist exited with 0, \n",
      "\n",
      "99f8b0228cc248376b70e54effdaa6d1f1c621b0483def828c76c235db8a03b7\n",
      "2021-10-18T14:32:14Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-10-18T14:32:14Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-92ab13472305c635c82eba291f53fb83-85e672356d22b00b-01 -sshRequired=false] \n",
      "2021/10/18 14:32:14 Got JobInfoJson from env\n",
      "2021/10/18 14:32:14 Starting App Insight Logger for task:  containerSetup\n",
      "2021/10/18 14:32:14 Version: 3.0.01744.0001 Branch: .SourceBranch Commit: f3a69a2\n",
      "2021/10/18 14:32:14 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/10/18 14:32:14 Starting infiniband setup\n",
      "2021/10/18 14:32:14 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/10/18 14:32:14 Returning Python Version as 3.7\n",
      "2021-10-18T14:32:14Z VMSize: standard_d13_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/10/18 14:32:14 VMSize: standard_d13_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/10/18 14:32:14 VMSize: standard_d13_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/10/18 14:32:14 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-10-18T14:32:14Z Not setting up Infiniband in Container\n",
      "2021/10/18 14:32:14 Not setting up Infiniband in Container\n",
      "2021/10/18 14:32:14 Not setting up Infiniband in Container\n",
      "2021/10/18 14:32:14 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/10/18 14:32:14 Returning Python Version as 3.7\n",
      "2021/10/18 14:32:14 sshd inside container not required for job, skipping setup.\n",
      "2021/10/18 14:32:15 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2021/10/18 14:32:15 App Insight Client has already been closed\n",
      "2021/10/18 14:32:15 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-10-18T14:32:15Z Starting docker container succeeded.\n",
      "2021-10-18T14:32:15Z The vmsize standard_d13_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt\n",
      "===============================================================================================================\n",
      "[2021-10-18T14:32:18.072440] Entering job preparation.\n",
      "[2021-10-18T14:32:19.523511] Starting job preparation.\n",
      "[2021-10-18T14:32:19.523561] Extracting the control code.\n",
      "[2021-10-18T14:32:19.523929] Starting extract_project.\n",
      "[2021-10-18T14:32:19.523980] Starting to extract zip file.\n",
      "[2021-10-18T14:32:19.542270] Finished extracting zip file.\n",
      "[2021-10-18T14:32:19.545865] Using urllib.request Python 3.0 or later\n",
      "[2021-10-18T14:32:19.545925] Start fetching snapshots.\n",
      "[2021-10-18T14:32:19.545982] Start fetching snapshot.\n",
      "[2021-10-18T14:32:19.546001] Retrieving project from snapshot: aa2647a0-1813-494c-b1c1-7c439ee32baf\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 55\n",
      "[2021-10-18T14:32:19.753504] Finished fetching snapshot.\n",
      "[2021-10-18T14:32:19.753552] Start fetching snapshot.\n",
      "[2021-10-18T14:32:19.753564] Retrieving project from snapshot: e9df1d43-12e8-446c-9eb7-3475e476bb9e\n",
      "[2021-10-18T14:32:26.058905] Finished fetching snapshot.\n",
      "[2021-10-18T14:32:26.058938] Finished fetching snapshots.\n",
      "[2021-10-18T14:32:26.058952] Finished extract_project.\n",
      "[2021-10-18T14:32:26.059019] Finished fetching and extracting the control code.\n",
      "[2021-10-18T14:32:26.067179] Start run_history_prep.\n",
      "[2021-10-18T14:32:26.078323] Job preparation is complete.\n",
      "[2021-10-18T14:32:26.078505] Entering Data Context Managers in Sidecar\n",
      "[2021-10-18T14:32:26.079426] Running Sidecar prep cmd...\n",
      "[2021-10-18T14:32:26.513490] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/azureml/9bb88f76-43a2-4327-942f-9c37a7645139\n",
      "[2021-10-18T14:32:26.514252] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      "[2021-10-18T14:32:26.707] Enter __enter__ of DatasetContextManager\n",
      "[2021-10-18T14:32:26.708] SDK version: azureml-core==1.33.0.post1 azureml-dataprep==2.22.2. Session id: 79097949-0209-4ac2-bb8d-6c7314be20d9. Run id: 9bb88f76-43a2-4327-942f-9c37a7645139.\n",
      "[2021-10-18T14:32:26.708] Processing 'train_10_models'.\n",
      "[2021-10-18T14:32:26.708] Mode: 'mount'.\n",
      "[2021-10-18T14:32:26.708] Path on compute is specified: 'False'.\n",
      "[2021-10-18T14:32:29.783] Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'oj_sales_data_train')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"158affca-d916-4a22-a0b5-98796258366b\",\n",
      "    \"name\": \"oj_data_small_train\",\n",
      "    \"version\": 2,\n",
      "    \"workspace\": \"Workspace.create(name='coding-forge-ml-ws', subscription_id='af3877c2-18a2-4ce2-b67c-a8e21e968128', resource_group='coding-forge-rg')\"\n",
      "  }\n",
      "}\n",
      "[2021-10-18T14:32:31.064] Mounting train_10_models to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/train_10_models_158affca-d916-4a22-a0b5-98796258366b as folder.\n",
      "[2021-10-18T14:32:31.118] Mounting train_10_models to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/train_10_models_158affca-d916-4a22-a0b5-98796258366b.\n",
      "[2021-10-18T14:32:32.125] Mounted train_10_models to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/train_10_models_158affca-d916-4a22-a0b5-98796258366b.\n",
      "[2021-10-18T14:32:32.220] Exit __enter__ of DatasetContextManager\n",
      "Set Dataset train_10_models's target path to /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/train_10_models_158affca-d916-4a22-a0b5-98796258366b\n",
      "Sidecar adding paths_to_bind: ['/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/tmpa2rsqdrn:/tmp/c4577e13-5476-4888-8a9c-476351f75408/07c6bea1-1859-4fd0-a924-e7eacb0bd228']\n",
      "Acquired lockfile /tmp/9bb88f76-43a2-4327-942f-9c37a7645139-datastore.lock to downloading input data references\n",
      "[2021-10-18T14:32:32.232356] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-10-18T14:32:32.831802] Ran Sidecar prep cmd.\n",
      "[2021-10-18T14:32:32.831907] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/10/18 14:34:09 Got JobInfoJson from env\n",
      "2021/10/18 14:34:09 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/10/18 14:34:09 Version: 3.0.01744.0001 Branch: .SourceBranch Commit: f3a69a2\n",
      "2021/10/18 14:34:09 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/info\n",
      "2021/10/18 14:34:09 Send process info logs to master server succeeded\n",
      "2021/10/18 14:34:09 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
      "2021/10/18 14:34:09 Send process info logs to master server succeeded\n",
      "[2021-10-18T14:34:09.447889] Entering context manager injector.\n",
      "[2021-10-18T14:34:10.087727] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/mounts/workspaceblobstore/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/many_models_training_output', '--process_count_per_node', '8', '--node_count', '2', '--input_fds_0', 'train_10_models'])\n",
      "Script type = None\n",
      "[2021-10-18T14:34:10.092917] Entering Run History Context Manager.\n",
      "[2021-10-18T14:34:12.662622] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/azureml/9bb88f76-43a2-4327-942f-9c37a7645139\n",
      "[2021-10-18T14:34:12.662913] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/mounts/workspaceblobstore/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/many_models_training_output', '--process_count_per_node', '8', '--node_count', '2', '--input_fds_0', 'train_10_models']\n",
      "[2021-10-18T14:34:12.662948] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/mounts/workspaceblobstore/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/many_models_training_output', '--process_count_per_node', '8', '--node_count', '2', '--input_fds_0', 'train_10_models']\n",
      "\n",
      "2021/10/18 14:34:14 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "\n",
      "[2021-10-18T14:39:50.798221] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "4 items cleaning up...\n",
      "Cleanup took 0.2632145881652832 seconds\n",
      "[2021-10-18T14:39:51.183276] Finished context manager injector.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt\n",
      "===============================================================================================================\n",
      "[2021-10-18T14:39:56.168296] Entering job release\n",
      "[2021-10-18T14:39:57.089108] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-10-18T14:39:57.089161] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-10-18T14:39:57.089293] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-10-18T14:39:57.089843] Running Sidecar release cmd...\n",
      "[2021-10-18T14:39:57.101135] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/azureml/9bb88f76-43a2-4327-942f-9c37a7645139\n",
      "[2021-10-18T14:39:57.114] Enter __exit__ of DatasetContextManager\n",
      "[2021-10-18T14:39:57.114] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/train_10_models_158affca-d916-4a22-a0b5-98796258366b.\n",
      "[2021-10-18T14:39:57.114] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/coding-forge-ml-ws/azureml/9bb88f76-43a2-4327-942f-9c37a7645139/wd/train_10_models_158affca-d916-4a22-a0b5-98796258366b.\n",
      "[2021-10-18T14:39:57.114] Exit __exit__ of DatasetContextManager\n",
      "[2021-10-18T14:39:57.114536] Removing absolute paths from host...\n",
      "[2021-10-18T14:39:57.123549] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-10-18T14:39:57.350485] Ran Sidecar release cmd.\n",
      "\n",
      "StepRun(many-models-train) Execution Summary\n",
      "=============================================\n",
      "StepRun( many-models-train ) Status: Finished\n",
      "{'runId': '9bb88f76-43a2-4327-942f-9c37a7645139', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2021-10-18T14:31:33.029562Z', 'endTimeUtc': '2021-10-18T14:40:10.436673Z', 'services': {}, 'properties': {'ContentSnapshotId': 'aa2647a0-1813-494c-b1c1-7c439ee32baf', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'ea2963f2-45e7-4ffd-b990-ca1a7d59e51f', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'b51fecf5', 'azureml.pipelinerunid': '5820d0fb-d764-48d4-a716-71fce75efe27', 'azureml.pipeline': '5820d0fb-d764-48d4-a716-71fce75efe27', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '158affca-d916-4a22-a0b5-98796258366b'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'train_10_models', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.35.0', '--scoring_module_name', 'many_models_train_driver.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '920', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_many_models_training_output', '--process_count_per_node', '8', '--node_count', '2', '--input_fds_0', 'train_10_models'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {'many_models_training_output': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/9bb88f76-43a2-4327-942f-9c37a7645139/many_models_training_output', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'train_10_models': {'dataLocation': {'dataset': {'id': '158affca-d916-4a22-a0b5-98796258366b', 'name': None, 'version': '2'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'train_10_models', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AutoML-AzureML-AutoML', 'version': 'Autosave_2021-10-18T13:21:16Z_6a587f33', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge', 'pytorch'], 'dependencies': ['python=3.6.2', 'pip=21.1.2', {'pip': ['azureml-core==1.34.0', 'azureml-pipeline-core==1.34.0', 'azureml-telemetry==1.34.0', 'azureml-defaults==1.34.0', 'azureml-interpret==1.34.0', 'azureml-responsibleai==1.34.0', 'azureml-automl-core==1.34.1', 'azureml-automl-runtime==1.34.1.post1', 'azureml-train-automl-client==1.34.0', 'azureml-train-automl-runtime==1.34.1', 'azureml-dataset-runtime==1.34.0', 'azureml-mlflow==1.34.0', 'inference-schema', 'py-cpuinfo==5.0.0', 'boto3==1.15.18', 'botocore==1.18.18']}, 'numpy~=1.18.0', 'scikit-learn==0.22.1', 'pandas~=0.25.0', 'py-xgboost<=0.90', 'fbprophet==0.5', 'holidays==0.9.11', 'setuptools-git', 'psutil>5.0.0,<6.0.0'], 'name': 'azureml_1b22a9c5d9b447e8fbdcc34171e02fe8'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1, 'location': None}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/55_azureml-execution-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt?sv=2019-07-07&sr=b&sig=wDz9lj1nRKDNbNQ2bfMkIouvy4Qyvu%2FkjijyCArB5Ik%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/55_azureml-execution-tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d.txt?sv=2019-07-07&sr=b&sig=KcNx1l3D8w%2FYpZSluJjfRY3ka8t90hvOA2qdlTwzW5E%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/65_job_prep-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt?sv=2019-07-07&sr=b&sig=pKt4%2FeS7gwkoN%2FHRNiNMeJTLes%2BuORv55OHqDkszo30%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/65_job_prep-tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d.txt?sv=2019-07-07&sr=b&sig=C8NYRECzh0V4WXnvyk4EdYrYCoWBk19MsmqVSMpi7hk%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=X9x5ead%2B4HaojT6KXmL3CI3iBJZszlHqYmcKZBu%2FSEk%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/75_job_post-tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d.txt?sv=2019-07-07&sr=b&sig=fX3TJqOELx%2FRodn5ODAhiNYGxGJW44yp3IT%2FDUMq6O0%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/75_job_post-tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d.txt?sv=2019-07-07&sr=b&sig=dp48h8JROfCSJbhO2BDL7B2NnKcBIxMC6T9SQVNedqs%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/process_info.json': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=uGthvuFae%2FGOwLAM6bglvoCDY2PkaCmymZk689Z5auU%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'azureml-logs/process_status.json': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=SQvWjwWmNhywsLeE8xM0Wx%2F6Ml0m00a%2Flzi3jWZqBWA%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/108_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/108_azureml.log?sv=2019-07-07&sr=b&sig=%2F1DDthZAPW%2FzH%2F0F8LL6ib%2B7h5fKsryo86Y%2FAJckZiA%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/93_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/93_azureml.log?sv=2019-07-07&sr=b&sig=ykLUUckV4bNCLfpV9Cvj91onJpZhg1FLd76U2Bu1Xmk%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=UXtiu5yWDyvZWP26qYrCt1KZvLsttxYvvGCksdrG53Y%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=8Dsiq9k8LppbXQ3VP4le9BsS%2B4xwkUhA2aSCwoJGxJc%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=pVEteN0LiNt7MZIswyK0Z1GqngUvy1gYIsnmpH6gnN8%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=hbElmW6MQHMjMer%2Bce4tfbiqsBoinU42wMeIarSiRbU%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=SUVe2QfgBTl7pde8I8BJITsBRE%2Bvrgf3cN3GpwvnkBE%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d/all.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/sidecar/tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d/all.log?sv=2019-07-07&sr=b&sig=qfracBfuwqxGDfdODdwHGII6dd7Ef0qXSdxsKjieGBw%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d/task.enter_contexts.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/sidecar/tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=FVt5D0xIZv0xCmLa7xdda1cNwkI7zSln2b%2FsBHduajU%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d/task.exit_contexts.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/sidecar/tvmps_7baa02f93d7b0648973a313840a43e868a523051fccf39fa971334b50cc7f281_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=UfbUG4WO1%2FViN08ISYLpdh3hRrjpy821Q2xlSQudPOc%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d/all.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/sidecar/tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d/all.log?sv=2019-07-07&sr=b&sig=xaREGupgEF9iwGm6QYeMoipkr8RiKy7vNYAF4B32fuY%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d/task.enter_contexts.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/sidecar/tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=UEYo2XkZaaOoNjLBUsr6iPYuIfwx9FoBX2gzkXEDTNA%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d/task.exit_contexts.log': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/sidecar/tvmps_d6cd04e23c3ff7936c1c012777bb7e763221a6cb5a5b249a8ddbaa39640d4f5b_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=WxAKWIw37oh6xfZ2n4atufg1ugjktVD7nd0K5i2%2BF10%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=8vf32QbWlJwQbwMQtnBCFWsNVUxvG12XkBE6BgW2GxI%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.9bb88f76-43a2-4327-942f-9c37a7645139/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=snHo%2B9yr36TFz%2FxgWbuB6UXUXuYnxFKreN7wr81e0SI%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A00Z&se=2021-10-18T22%3A40%3A00Z&sp=r'}, 'submittedBy': 'Brandon Campbell'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '5820d0fb-d764-48d4-a716-71fce75efe27', 'status': 'Completed', 'startTimeUtc': '2021-10-18T14:26:43.877472Z', 'endTimeUtc': '2021-10-18T14:40:13.046188Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.5820d0fb-d764-48d4-a716-71fce75efe27/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=VY6gq6uDCGm%2FLYtxstTNKgdKCI6VgTTQIrAPK%2FJgLmY%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A14Z&se=2021-10-18T22%3A40%3A14Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.5820d0fb-d764-48d4-a716-71fce75efe27/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=1UP18eAJPSa1fpOKlfoJcl6o27Dw1Svk8WPg0wIaI8o%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A14Z&se=2021-10-18T22%3A40%3A14Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://codingforgesa.blob.core.windows.net/azureml/ExperimentRun/dcid.5820d0fb-d764-48d4-a716-71fce75efe27/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=oWI3O6OFnZQqN0jvXM3krYacOwNsOyNiJJOgABcMxsY%3D&skoid=62dda26f-3571-42bf-8c44-ccb3db7f889b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-18T13%3A11%3A13Z&ske=2021-10-19T21%3A21%3A13Z&sks=b&skv=2019-07-07&st=2021-10-18T14%3A30%3A14Z&se=2021-10-18T22%3A40%3A14Z&sp=r'}, 'submittedBy': 'Brandon Campbell'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run.wait_for_completion(show_output=True)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully trained, registered Automated ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Review outputs of the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training pipeline will train and register models to the Workspace. You can review trained models in the Azure Machine Learning Studio under 'Models'.\n",
    "If there are any issues with training, you can go to 'many-models-training' run under the pipeline run and explore logs under 'Logs'.\n",
    "You can look at the stdout and stderr output under logs/user/worker/<ip> for more details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Get list of AutoML runs along with registered model names and tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will iterate through all the automl runs for the experiment and list the details.\n",
    "\n",
    "**Framework** - AutoML, **Dataset** - input data set, **Run** - AutoML run id, **Status** - AutoML run status,  **Model** - Registered model name, **Tags** - Tags for model, **StartTime** - Start time, **EndTime** - End time, **ErrorType** - ErrorType, **ErrorCode** - ErrorCode, **ErrorMessage** - Error Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helper import get_training_output\n",
    "import os\n",
    "\n",
    "training_results_name = \"training_results\"\n",
    "training_output_name = \"many_models_training_output\"\n",
    "\n",
    "#training_file = get_training_output(run, training_results_name, training_output_name)\n",
    "training_file = get_training_output(pipeline_run, training_results_name, training_output_name)\n",
    "all_columns = [\"Framework\", \"Dataset\", \"Run\", \"Status\", \"Model\", \"Tags\", \"StartTime\", \"EndTime\" , \"ErrorType\", \"ErrorCode\", \"ErrorMessage\" ]\n",
    "df = pd.read_csv(training_file, delimiter=\" \", header=None, names=all_columns)\n",
    "training_csv_file = \"training.csv\"\n",
    "df.to_csv(training_csv_file)\n",
    "print(\"Training output has\", df.shape[0], \"rows. Please open\", os.path.abspath(training_csv_file), \"to browse through all the output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Publish and schedule the pipeline (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Publish the pipeline\n",
    "\n",
    "Once you have a pipeline you're happy with, you can publish a pipeline so you can call it programmatically later on. See this [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#publish-a-pipeline) for additional information on publishing and calling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "pipelineEndpointName = 'automl_train_many_models'\n",
    "\n",
    "published_pipeline = pipeline.publish(name = 'automl_train_many_models',\n",
    "                                  description = 'train many models',\n",
    "                                  version = '1',\n",
    "                                  continue_on_step_failure = False)\n",
    "\n",
    "\n",
    "if pipelineEndpointName in str(PipelineEndpoint.list(ws)):\n",
    "    # Add a new Version to an existing Endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.get(workspace = ws, name = pipelineEndpointName)\n",
    "    pipeline_endpoint.add_default(published_pipeline)\n",
    "else:\n",
    "    # Create a new Endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.publish(workspace = ws,\n",
    "                                                name = pipelineEndpointName,\n",
    "                                                pipeline = published_pipeline,\n",
    "                                                description = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Schedule the pipeline\n",
    "You can also [schedule the pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines) to run on a time-based or change-based schedule. This could be used to automatically retrain models every month or based on another trigger such as data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# training_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"automl_training_recurring_schedule\", \n",
    "#                             description=\"Schedule Training Pipeline to run on the first day of every month\",\n",
    "#                             pipeline_id=training_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Bookkeeping of workspace (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Cancel any runs that are running\n",
    "\n",
    "To cancel any runs that are still running in a given experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.helper import cancel_runs_in_experiment\n",
    "# failed_experiment =  'Please modify this and enter the experiment name'\n",
    "# # Please note that the following script cancels all the currently running runs in the experiment\n",
    "# cancel_runs_in_experiment(ws, failed_experiment)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "interpreter": {
   "hash": "3fec610cbb67958716dc318121910cfa04ded6f5645ced1eebbb9789e5469472"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('azureml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
